---
title: "Learning Dagster from Airflow"
description: How to get started with Dagster from an Airflow background
---

# Learning Dagster from Airflow

In this tutorial, we'll help you make the switch from Airflow to Dagster. Here, we review an Airflow DAG and show how the same functionality can be achieved in Dagster.

---

## Comparing an Airflow DAG to Dagster

In this tutorial, we'll rewrite an [Airflow DAG](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/fundamentals.html) as a Dagster [job](/concepts/ops-jobs-graphs/jobs). Let's start with a basic Airflow DAG:

```python file=/integrations/airflow/dags/tutorial.py
from datetime import datetime, timedelta
from textwrap import dedent

from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
    "tutorial",
    default_args={
        "retries": 1,
    },
    description="A simple tutorial DAG",
    schedule_interval=timedelta(days=1),
    start_date=datetime(2021, 1, 1),
    catchup=False,
    tags=["example"],
) as dag:
    t1 = BashOperator(
        task_id="print_date",
        bash_command="date",
    )

    t2 = BashOperator(
        task_id="sleep",
        bash_command="sleep 5",
        retries=3,
    )

    templated_command = dedent(
        """
    {% for i in range(5) %}
        echo "{{ ds }}"
        echo "{{ macros.ds_add(ds, 7)}}"
    {% endfor %}
    """
    )

    t3 = BashOperator(
        task_id="templated",
        bash_command=templated_command,
    )

    t1 >> [t2, t3]
```

To rewrite this DAG in Dagster, we'll break it down into three parts:

1. Define the computations: the ops - in Airflow, the operators
2. Define the graph: the job - in Airflow, the DAG
3. Define the schedule - In Airflow, the schedule (how simple!)

A Dagster [job](/concepts/ops-jobs-graphs/jobs) is made up of a [graph](/concepts/ops-jobs-graphs/graphs) of [ops](/concepts/ops-jobs-graphs/ops). This should feel familiar if you've used the Airflow Task API. With ops, the focus is on writing a graph with Python functions as nodes and data dependencies in between them as edges.

---

## Step 1: Defining the ops

In Dagster, the minimum unit of computation is an op. This directly corresponds to an operator in Airflow. Here, we map the operators of our example Airflow DAG `t1`, `t2`, and `t3` to their respective Dagster ops.

```python file=/integrations/airflow/tutorial_rewrite_dagster.py startafter=start_ops endbefore=end_ops
@op
def print_date(context: OpExecutionContext) -> datetime:
    ds = datetime.now()
    context.log.info(ds)
    return ds


@op(retry_policy=RetryPolicy(max_retries=3), ins={"start": In(Nothing)})
def sleep():
    time.sleep(5)


@op
def templated(context: OpExecutionContext, ds: datetime):
    for _i in range(5):
        context.log.info(ds)
        context.log.info(ds - timedelta(days=7))
```

Which would yield the following graph of computations in the Dagster UI. We'll spin up the UI later in the tutorial, but wanted to demonstrate:

<center>
  <Image
    alt="Screenshot of the dagster UI, showing the newly created graph of tutorial Ops"
    src="/images/integrations/airflow/airflow_tutorial_rewrite_ops.png"
    width={2200}
    height={1300}
  />
</center>

### Op-level retries

In the tutorial DAG, the `t2` operator allowed for three retries. To configure the same behavior in Dagster, you can use [op-level retry policies](/concepts/ops-jobs-graphs/op-retries).

---

## Step 2: Define the job

In Dagster, the computations defined in ops are composed in jobs, which define the sequence and dependency structure of the computations you want to execute. This directly corresponds to a DAG in Airflow. Here, we compose the op's `print_date`, `sleep` and `templated` to match the dependency structure defined by the Airflow operators `t1`, `t2`, and `t3`.

```python file=/integrations/airflow/tutorial_rewrite_dagster.py startafter=start_job endbefore=end_job
@job(tags={"dagster/max_retries": 1, "dag_name": "example"})
def tutorial_job():
    ds = print_date()
    sleep(ds)
    templated(ds)
```

### Job-level retries

Job-level retries are managed by the [run launcher](/deployment/run-retries). Once enabled in your `dagster.yaml` file, you can define the retry count for the job.

---

## Step 3: Define the schedule

In Dagster, schedules can be defined for jobs, which determine the cadence at which a job is triggered to be executed. Below we define a schedule that will run the `tutorial_job` daily:

```python file=/integrations/airflow/tutorial_rewrite_dagster.py startafter=start_schedule endbefore=end_schedule
schedule = ScheduleDefinition(job=tutorial_job, cron_schedule="@daily")
```

---

## Step 4: Run Dagster locally

In order to run our newly defined Dagster job we'll need to add it and the schedule to our project's [Definitions](/concepts/code-locations#defining-code-locations).

```python file=/integrations/airflow/tutorial_rewrite_dagster.py startafter=start_repo endbefore=end_repo
defs = Definitions(
    jobs=[tutorial_job],
    schedules=[schedule],
)
```

We can now load this file with the UI:

```bash
dagster dev -f <your_dagster_file>.py
```

---

## Completed code example

That's it! By now, your code should look like this:

```python file=/integrations/airflow/tutorial_rewrite_complete.py startafter=start_example endbefore=end_example
import time
from datetime import datetime, timedelta

from dagster import (
    Definitions,
    In,
    Nothing,
    OpExecutionContext,
    RetryPolicy,
    ScheduleDefinition,
    job,
    op,
    schedule,
)


@op
def print_date(context: OpExecutionContext) -> datetime:
    ds = datetime.now()
    context.log.info(ds)
    return ds


@op(retry_policy=RetryPolicy(max_retries=3), ins={"start": In(Nothing)})
def sleep():
    time.sleep(5)


@op
def templated(context: OpExecutionContext, ds: datetime):
    for _i in range(5):
        context.log.info(ds)
        context.log.info(ds - timedelta(days=7))


@job(tags={"dagster/max_retries": 1, "dag_name": "example"})
def tutorial_job():
    ds = print_date()
    sleep(ds)
    templated(ds)


schedule = ScheduleDefinition(job=tutorial_job, cron_schedule="@daily")


defs = Definitions(
    jobs=[tutorial_job],
    schedules=[schedule],
)
```

---

## Mapping Airflow concepts to Dagster

While Airflow and Dagster have some significant differences, there are many concepts that overlap. Use this cheatsheet to understand how Airflow concepts map to Dagster.

<table
  className="table"
  style={{
    width: "100%",
  }}
>
  <thead>
    <tr>
      <th
        style={{
          width: "25%",
        }}
      >
        Airflow concept
      </th>
      <th
        style={{
          width: "30%",
        }}
      >
        Dagster concept
      </th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Directed Acyclic Graphs (DAG)</td>
      <td>
        <a href="/concepts/ops-jobs-graphs/jobs">Jobs</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Task</td>
      <td>
        <a href="/concepts/ops-jobs-graphs/ops">Ops</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Datasets</td>
      <td>
        <a href="/concepts/assets/software-defined-assets">Assets</a>
      </td>
      <td>
        Dagster assets are more powerful and mature than datasets and include
        support for things like{" "}
        <a href="/concepts/partitions-schedules-sensors/partitioning-assets">
          partitioning
        </a>
        .
      </td>
    </tr>
    <tr>
      <td>Connections/Variables</td>
      <td>
        <ul style={{ marginTop: "0em" }}>
          <li style={{ marginTop: "0em" }}>
            <a href="/concepts/configuration/config-schema">
              Run configuration
            </a>
          </li>
          <li>
            <a href="/concepts/configuration/configured">Configured API</a>{" "}
            (Legacy)
          </li>
          <li>
            <a href="/guides/dagster/using-environment-variables-and-secrets">
              Environment variables
            </a>{" "}
            (Dagster+ only)
          </li>
        </ul>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>DagBags</td>
      <td>
        <a href="/concepts/code-locations">Code locations</a>
      </td>
      <td>
        Multiple isolated code locations with different system and Python
        dependencies can exist within the same Dagster instance.
      </td>
    </tr>
    <tr>
      <td>DAG runs</td>
      <td>Job runs</td>
      <td></td>
    </tr>
    <tr>
      <td>
        <code>depends_on_past</code>
      </td>
      <td>
        <ul style={{ marginTop: "0em" }}>
          <li style={{ marginTop: "0em" }}>
            <a href="/concepts/partitions-schedules-sensors/partitions">
              Partitions
            </a>
          </li>
          <li>
            <a href="/concepts/partitions-schedules-sensors/backfills">
              Backfills
            </a>
          </li>
          <li>
            <a href="/concepts/automation/declarative-automation">
              Declarative Automation
            </a>
          </li>
        </ul>
      </td>
      <td>
        An asset can{" "}
        <a
          href="https://github.com/dagster-io/dagster/discussions/11829"
          target="new"
        >
          depend on earlier partitions of itself
        </a>
        . When this is the case, <a href="/concepts/partitions-schedules-sensors/backfills">
          backfills
        </a> and <a href="/concepts/automation/declarative-automation">
          Declarative Automation
        </a> will only materialize later partitions after earlier partitions have
        completed.
      </td>
    </tr>
    <tr>
      <td>Executors</td>
      <td>
        <a href="/deployment/executors">Executors</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Hooks</td>
      <td>
        <a href="/concepts/resources">Resources</a>
      </td>
      <td>
        Dagster <a href="/concepts/resources">resource</a> contain a superset of
        the functionality of hooks and have much stronger composition
        guarantees.
      </td>
    </tr>
    <tr>
      <td>Instances</td>
      <td>
        <a href="/deployment/dagster-instance">Instances</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Operators</td>
      <td>None</td>
      <td>
        Dagster uses normal Python functions instead of framework-specific
        operator classes. For off-the-shelf functionality with third-party
        tools, Dagster provides{" "}
        <a href="/integrations">integration libraries</a>.
      </td>
    </tr>
    <tr>
      <td>Pools</td>
      <td>
        <a href="/deployment/run-coordinator">Run coordinators</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Plugins/Providers</td>
      <td>
        <a href="/integrations">Integrations</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Schedulers</td>
      <td>
        <a href="/concepts/automation/schedules">Schedules</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Sensors</td>
      <td>
        <a href="/concepts/partitions-schedules-sensors/sensors">Sensors</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>SubDAGs/TaskGroups</td>
      <td>
        <ul style={{ marginTop: "0em" }}>
          <li style={{ marginTop: "0em" }}>
            <a href="/concepts/ops-jobs-graphs/graphs">Graphs</a>
          </li>
          <li>
            <a href="/concepts/metadata-tags/tags">Tags</a>
          </li>
          <li>
            <a href="/concepts/assets/software-defined-assets#grouping-assets">
              Asset groups
            </a>
          </li>
        </ul>
      </td>
      <td>
        Dagster provides rich, searchable{" "}
        <a href="/concepts/metadata-tags">
          metadata and <a href="/concepts/metadata-tags/tags">tagging</a>
        </a>{" "}
        support beyond what’s offered by Airflow.
      </td>
    </tr>
    <tr>
      <td>
        <code>task_concurrency</code>
      </td>
      <td>
        <a href="/guides/limiting-concurrency-in-data-pipelines#limiting-opasset-concurrency-across-runs">
          Asset/op-level concurrency limits
        </a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>Trigger</td>
      <td>
        <a href="/concepts/webserver/ui">Dagster UI Launchpad</a>
      </td>
      <td>
        Triggering and configuring ad-hoc runs is easier in Dagster which allows
        them to be initiated through the{" "}
        <a href="/concepts/webserver/ui">Dagster UI</a>, the{" "}
        <a href="/concepts/webserver/graphql">GraphQL API</a>, or the CLI.
      </td>
    </tr>
    <tr>
      <td>XComs</td>
      <td>
        <a href="/concepts/io-management/io-managers">I/O managers</a>
      </td>
      <td>
        I/O managers are more powerful than XComs and allow the passing large
        datasets between jobs.
      </td>
    </tr>
  </tbody>
</table>
